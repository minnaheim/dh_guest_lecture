---
title: "Guest Lecture: Open Time Series Initiative"
format: revealjs
---

## About me 
:::: {.columns}

::: {.column width=60%}
- took this course 3 years ago!
- graduated from my bachelor's in economics at HSG just 20 days ago 
- pursuing a MSc Data Science with a minor in Economics UZH
- work at the Swiss Economic Institute at ETH

:::

::: {.column width=40%}
![](muster_bild.jpeg)
<!-- insert graduation picture -->

<!-- with this presentation, want to give more context into what you have been learning and one of the multitude of things you could do with data handling-->
:::
::::

# Why am I here today?
<!-- My team and I at KOF-ETH are working on a framework that makes public data more machine readable. But what does this even mean?

To answer this question, we will cover a bit of what you've learnt in class, and we'll put this into context -->


## What you've learnt till now

- different data for different purposes
- xml, html, csv, etc. (csv for structural data, json / nested data for non-structural data, higher level information)
- sounds easy so far...

## In Practice
- Most data accessible to you and me is due to public data providers (BFS, SECO, etc.)
- but since their data customers are so diverse, they sometimes publish in weird formats...

## Case Study BFS
- cater to the general public - people interested in data, but also researchers, etc. 
- what the hell is .px data - i didnt know either, with swissdata you dont need to...
<!-- example of .px data -->

```r
import px data
```

<!-- example of pdf data, px data -->

## A Researcher's Perspective
- data importing, handling and cleaning is most of the work
- by simplifying the process of data importing and cleaning, we could save researchers a lot of time

## So, what does Opentsi do?
- framework which not only makes time series data more machine readable, but also aims to make the storage of time series vintages better...

## illustration of splitting data


<!-- instead of showing code, i could do a little demo, pretend you are a researcher... -->
# Under the hood
# So Fresh, So Clean
- splits .px data into two types of files: csv & json

## Get BFS Time Series

The regular procedure would be the following:

```r
library(readxl)
cpi <- read_excel("cpi_regular.xlsx")
```
```{r}
library(readxl)
library(tidyverse)
cpi <- read_excel("cpi_regular.xlsx")
head(cpi)
view(cpi)
```

## With Open Time Series 

The procedure would be the following:
```r
# create folder structure to save data
options(swissdata.wd = "../swissdata")
set_update_all()
library(devtools)
install_github("mbannert/swissdata")
```

```{r}
# library(devtools)
# install_github("mbannert/swissdata")
library(readxl)
options(swissdata.wd = "../swissdata")
library(swissdata)

# download cleaned dataset if it already exists pre-cleaned
# set_download("ch.fso.cpi")

cpi <- read_excel("../swissdata/ch.fso.cpi/download/cpi.xlsx")

```

<!-- only read_swissdata_meta() has documentation?
cpi_2 <- download_fso_excel(32767551)
view(cpi_2) # didnt work, i just get /var/folders/... -->
## before: .px

## after: .csv & .json

# DeloRean - Time Machine
- time series data vintages for forecasting
- storing in an academic way, low budget & open source

## If you're interested in collaboration
- find us on...
- contact me through...
- use this for your thesis?


<!-- insert illustractions of:
- time series data 
- meta data
- csv data 
- transformation 
-->